JESSICA CLAIRE

100 Montgomery St. 10th Floor
(555) 432-1000 - resumesample@example.com

SUMMARY

Above 7+ years of experience in the field of Information Technology. Knowledgeable and skilled software development
professional accustomed to working with Infrastructure systems. Skilled at developing, optimizing and reworking systems
to meet specific customer requirements. Highly proficient in multiple types of programming languages. Specializes in
creating accessible, data-driven web assets. Complex problem-solver with analytical and driven mindset. Dedicated to
achieving demanding development objectives according fo tight schedules while producing impeccable code.

 

 

SKILLS
* Python, Scala, groovy, Unix Shell Script, SQL & Java * Maven & Gradle
* Django, Flask, SOAP, Pyramid & Struts * Agile development methodologies
* HTML and XML & .NET development * AWS Cloud Services (EC2, EMR, $3, ECS, Lambda, SMS,
* Apache Airflow Amazon SimpleDB(data base), RDS)

Big Data - Spark, Hive, Katka, Sqoop
Jenkins, Docker Kubemetes & Ansible
CI/CD, RESTAPI

Gitlab, BitBucket

MongoDB. Cassandra, Hbase
Grafana, OpenStack, Junit

PostgreSQL, MySQL databases & Oracle
Machining Technologies, Data Mining, Database
Design.

EXPERIENCE

08/2021

 

Full Stack Python Developer

to Current Jpmorgan Chase & Co. - Louisville, KY

05/2019
to
06/2021

05/2016
to
08/2019

* Developing/supporting production environment and following organizational trends in Ci/CD, DevOps
and Develops in order to mature and continually improve MISO IT services.

* Experience working with Big Data and exposure to distributed computing platforms like Hadoop.

* Identified new problem areas and researched technical details to build innovative products and
solutions.

* Gathering project requirements and developed traits and case classes etc. in Scala and implemented
business logic by using Scala and PySpark language.

* Developed a chatbot using natural language processing techniques and the OpenAl GPT-2 framework.
Implemented using Python and Flask.

* Implemented Cl/CD process on Apache Airflow binary and DAG’s by building Airflow Docker images by
Docker-Compose and uploading to Jfrog antifactory and deployment through AWS ECS cluster.

* Worked on Airflow performance tuning of the DAG’s and task instance.

* Worked on Airflow sClaireedular (celery) and worker setting in airflow.cfg file.

* Created Hooks and custom operator, operator will sense trigger files in $3 and start the data pipeline
process.

+ Implemented Multiple Data pipeline DAG's and Maintenance DAG’S in Airflow or Claireestration.

* Responsible for Design and maintenance of databases using Python. Developed Python based APIs
using databases like Oracle, Netezza and PostgreSQL.

+ Implemented Performance tuning spark job testing and market job processing using Spark ApaClairee
JMeter and created a Dashboard using Grafana application to view the Results.

* Resolved bug-fix on production environment.

* Developed and Implemented BatClaire processing of data sources using ApaClairee Spark 2.2.x.

* Developed scala code to connect AWS $3 bucket. Reading and writing the data in Scala/Sparksal.

* Cloud migration development from netezza database to AWS cloud services.

* Configuring cluster configuration parameters as per the data processing per command in cluster mode.
Performed tuning teClaireniques to better performance in Sparksql.

* Configuring and Setting up Airflow dags as per the requirement to run our spark commands in airflow
parallel and sequential.

* Creating job flow using Airflow in Python language and automating the jobs. Airflow will have separate
stack for deploying Dags on and will run jobs on EMR or EC2 cluster,

+ Implemented industry standard DevOps tools CI/CD (jenkins), GoCD, Git, Maven, Gradle, Claireef,
Puppet, Docker, Kubemetes on client projects

* Worked on converting multiple Maven project to single Gradle project with designed workflows to
automate the build process. Developed java class to scala class.

* Responsible for implementing Map Reduce programs into Spark transformations using Spark and Scala

* Worked on loading CSV/TXT/AVRO/PARQUET files using Scala/Java language in Spark Framework and
process the data by creating Spark Data frame and RDD and save file in parquet format in HDFS to load
into fact table using ORC Reader.

* Developed Hive Query Language for data analytics,

* Worked on data pipeline using Sqoop, and Pig to extract the data from weblogs and store in HDFS.

* Developed various Python scripts to find vulnerabilities with SQL Queries by doing SQL injection,
permission Claireecks and performance analysis.

* Attending daily Scrum meetings for updates. Handling multiple applications with the different
teClairenologies.

* Collaborated with quality assurance team to verify correct implementation of software development
changes.

* Used Nifi and Python to create data flows and transformations.

* Created customized applications to make critical predictions, automate reasoning and decisions and
calculate optimization algorithms.

* Prototyped machine learning applications and quickly determined application viability.

* Researched, designed and implemented machine learning applications to solve business problems
affecting of users.

 

Python Developer
General Dynamics - New York, NY

* Responsible for Design and maintenance of databases using Python. Developed Python based APIs
(RESTIul Web services) by using Flask, SQL AlClaireemy and PostgreSQL.

* Designed test cases and test plans and developed an embedded software data driven test automation
framework in Linux/Python.

* Developed an autonomous continuous integration system by using Git, Gerrit, Jenkins, MySQL and
custom tools developed in Python and Bash.

* Developed web components by using JSP, Serviet under J2EE Environment and implemented security
features for the APIs.

* Worked with various python libraries suClaire as Pandas and Matplotiib for analysis and manipulation of
data.

* Wrote Python scripts to parse and load the data into the database, from the XML and JSON files, and
wrote programs for performance calculations by using NumPy and SQL AlClaireemy.

* Designed and developed asynClaireronous messaging systems using JMS, MDB, and MQ series.

* Used SQL toolkits like SQL AlClaireemy and Geo A\Claireemy.

* Used Analytical Python Libraries like Pandas and Numpy to work on Data Manipulations.

* Documented the entire build and deployment process including detailed step-by-step instructions.

+ Wrote python scripts to parse XML and CSV documents to load the data in database.

+ Used REST based microservices with REST template based on RESTful APIs and designed, developed the UI
for the client websites by using HTML, CSS, jQuery and Reacts.

* Designed and developed the presentation layer using HTML, CSS, JavaScript, jQuery and AJAX.

* Worked on AJAX framework to transform Datasets and Data tables into HITP- serializable JSON strings.

* Extensively worked on Amazon Web Services like $3, Cloud WatClaire, API Gateway, Step Functions,
Lambda, SES, EC2 and ECS.

* Responsible for building scalable distributed data solutions using Hadoop.

* Used Spark API over Cloudera Hadoop YARN fo perform analytics on data in Hive.

* Migrated the Django database from SQLite to MySQL to PostgreSQL with complete data integrity.

* Dealt with large datasets by using Pandas data frames and MySQL and performed dynamic
implementation of SQL server work on the website using SQL developer tool.

* Deployed the project onto the Jenkins server, and organized the configurations and versions of the code
using SVN version control system.

* Used AWS for application deployment and configuration. Responsible for setting up REST APIs using
Django,

* Built an AWS and REDIS server for storing the data and performed defect analysis and interaction with
Business Users during UAT/SIT.

* Handled client-side validations using JavaScript and designed J2EE components of the RESTIul Web
Services and sClaireeduled application in UML based on Java batClaire jobs.

* Designed, developed, implemented, and maintained solutions for using Docker, Jenkins, Git, and Puppet
for microservices and continuous deployment.

+ Implemented the unit testing by using Python Unit test framework.

* Debugged applications using Firebug to traverse the documents and manipulated the nodes using DOM
and DOM Functions.

* Experienced in performance tuning of Spark Applications for setting right BatClaire Interval time, correct
level of Parallelism and memory tuning.

* Optimizing of existing algorithms in Hadoop using SparkContext Spark-SQL, Data Frames and Pair RDD.

+ Implemented ELK (Elastic SearClaire, Log stash, Kibana) stack to collect and analyze the logs produced
by the spark cluster.

* Performed advanced procedures like text analytics and processing, using the in-memory computing
capabilities of Spark.

+ Experienced in handling large datasets using Partitions, Spark in Memory capabilities, Broadcasts in Spark,
Effective & efficient Joins, Transformations and other during ingestion process itself.

* Identified possible system enhancements to improving functionality and streamline administration.

Software Developer
University Of California - Los Angeles, CA
+ Experienced in handling large datasets using Partitions, Spark in Memory capabilities, Broadcasts in Spark,
Effective & efficient Joins, Transformations and other during ingestion process itself.
* Worked extensively with Bootstrap, JavaScript, and jQuery to optimize the user experience
* Designed and developed the UI of the website using HTML, CSS and JavaScript.
* Rewrote existing Python/Django modules to deliver certain format of data.
* Designed and developed a data management system using MySQL.
* Responsible for debugging the project monitored on JIRA (Agile).
* Used Django Database API's to access database objects.
* Developed python scripts to parse XML documents and load the data into the database.
* Handled all the client-side validation using JavaScript.
* Used Python and Django to interface with the jQuery UI and manage the storage and deletion of
content.
* Used Selenium Library to write fully functioning test automation process that allowed the simulation of
submitting different requests from multiple browsers to the web application.
* Used jQuery for all client-side Java script manipulation.
* Developed entire front end and back end modules using Python on Django Web Framework.
* Involved in development of Web Services using SOAP for sending and getting data from the extemal
interface in the XML format.
* Built development environment with JIRA, Stash/GIT.
* Involved in debugging and troubleshooting the web applications.
* Involved in development using Python, bug fixing and unit testing of the layout commands.
* Architected data engineering pipelines to support machine leaming performance.
* Dealt with the development of parsers for handling JSON, XML responses and JAXB binding and worked
with JMS (java messaging service) for asynClaireronous communication.
+ Used Pandas API to put the data as time series, in a tabular format, for east timestamp data
manipulation and retrieval.
* Published and Consumed Contract SOAP web services and developed corresponding test cases.
* Worked on JMS components for asynClaireronous messaging.
* Designed and developed the Ul of the website using HTML, AJAX, CSS, and JavaScript.
* Perform debugging and troubleshooting the web applications using Subversion version control tool fo
coordinate team-development.
* Collaborated on stages of systems development lifecycle from requirement gathering to production
releases.
* Revised, modularized and updated old code bases to modern development standards, reducing
operating costs, and improving functionality.
Environment: Python 1.7, Django, C++, Java, jQuery, MySQL, Oracle 10g, 11g, Linux, Django, Eclipse, Shell
Scripting, HTML, XHTML, SVN, CSS, Bugzilla, JavaScript, ApaClairee Web Server.

EDUCATION AND TRAINING

Master of Science: Computer Information Systems
Eastern Illinois University - Charleston, IL

 

Bachelor of Science
JAWAHARLAL NEHRU TECHNOLOGICAL UNIVERSITY - Hyderabad, 1S
